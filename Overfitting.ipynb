{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">I am not following you here. As we discussed it, I do not think that overfitting is a meaningful way of arguing in the context of tomography (given informationally complete data). By definition, the purpose of quantum state tomography is to identify the quantum state that approximates the measurement data best; this leaves little room for interpretation about avoiding unavoidable fluctuations.\n",
    "\n",
    "I think there are issues of confusion here. So I am writing a long reply.\n",
    "\n",
    "<h2>Introduction and summary of major points</h2>\n",
    "\n",
    "<ol>\n",
    "\n",
    "<li>Issues of overfitting are about trying not to fit too closely to the data since real data is finite and has noise, etc. But since in any situation we do not know which aspects of the data are the fluctuations and which are the true trend the rule of thumb is to choose the simplest model that offers reasonable fit to the data.\n",
    "\n",
    "There is always then a tradeoff between model complexity and the accuracy of fit to data. If two models offer reasonably comparable fits to data, one would prefer the model of less complexity since it is expected to generalize better.\n",
    "\n",
    "<li>Informationally complete data does not mean that the data is sufficient to find the true underlying physical state. This is because of stochastic nature of the measurements. \n",
    "\n",
    "For example, given a classical coin, informationally complete data would be a set of coin tosses giving heads/tails. But even after a thousand tosses, that turn out to be let's say 499 heads and 501 tails, whether the coin's  underlying probability is 0.500 or 0.499 cannot be answered since the data is statistically insignificant for such a question. There is good evidence, however, that the underlying probability is not 0.3 for example.\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tomography and where we disagree.</h2>\n",
    "\n",
    "For a concrete example of tomography, let us consider qubits for which informationally complete data is the measurements along all the Pauli matrices. Let's say I measure a qubit along the z-axis and get 499 ups and 501 downs. \n",
    "\n",
    "I believe your stance is that the reconstructed state should look like (upto normalization):\n",
    "\n",
    "$|\\Psi\\rangle \\approx \\sqrt{0.499}|\\uparrow\\rangle + \\sqrt{0.501}|\\uparrow\\rangle$\n",
    "\n",
    "since this is the only true representation of what was measured in experiment. Your stance is (I think) the goal of tomography is to reliably fit to the data as well as possible without any other consideration. Issues of overfitting therefore shouldn't arise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The stance I am taking</h2>\n",
    "\n",
    "I believe that whenever there are two models such that \n",
    "<ol>\n",
    "<li>they have reasonably comparable fit to the data such that the difference in their validity is not statistically significant, and\n",
    "<li>one of them has lower complexity than the other, then\n",
    "</ol>\n",
    "    \n",
    "the simpler model should be chosen. I should point out that this seems to be the approach taken by the machine learning community.\n",
    "\n",
    "Now I will need to answer the following questions:\n",
    "\n",
    "<ol>\n",
    "<li>What will be the criteria to judge statistical significance of difference in validity?\n",
    "<li>Why should one choose the simpler model?\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Why should one choose the simpler model?</h2>\n",
    "\n",
    "There are two inter-related reasons and one weak reason:\n",
    "\n",
    "<ol>\n",
    "<li>Bayes' theorem\n",
    "    \n",
    "The Bayes' theorem tells us that given experimental data, the posterior probability for the model generating the data would be\n",
    "\n",
    "$$P(\\text{model}|\\text{data}) \\propto P(\\text{model}) \\times P(\\text{data}|\\text{model})$$\n",
    "\n",
    "where $P(\\text{data}|\\text{model})$ is the likelihood function which our machine learning already seeks to maximize and $P(\\text{model})$ is the prior distribution for the model.\n",
    "\n",
    "Such a formula provides more weightage to a simpler model because of Occam's razor. For example, see Chapter 28 of the book \"Information Theory, Inference, and Learning Algorithms\" from where I borrow:\n",
    "\n",
    "><q>A simple model H1 makes only a limited range of predictions; a more powerful model H2, that has, for example, more free parameters than H1, is able to predict a greater variety of datasets. This means, however, that H2 does not predict the datasets in region C1 as strongly as H1. Suppose that equal prior probabilities have been assigned to the two models. Then, if the data set falls in region C1,the less powerful model H1 will be the more probable model.</q>\n",
    "\n",
    "<li>Overfitting\n",
    "    \n",
    "A related reason is overfitting. \n",
    "\n",
    "Any real-life data has noise so that the true model may not exactly fit the data. But given the data, we never know which part reflects the true trend and which is due to statistical fluctuations. What one may assume then is that the statistical fluctuations are small so that the true model will fit it upto statistical insignificant amounts.\n",
    "\n",
    "A notion in machine learning is to allow for such statistically insignificant deviations from the true fit if that leads to simple model. Again since simple models have lower number of parameters they have learnt the data better than complex models.\n",
    "\n",
    "<li> Simple models are easy to understand and manipulate. The goal is to best reconstruct a wavefunction which can generate the data and it's an added bonus if it comes in a simple to understand-and-manipulate form.\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Applying to our project</h2>\n",
    "\n",
    "I will now apply these considerations to our project.\n",
    "\n",
    "Let us assume the following:\n",
    "\n",
    "<ol>\n",
    "<li> The tomographic data may be complete but will always have statistical fluctuations such that we should allow the possible reconstructions of the wave-function to deviate from the data by statistically insignificant amounts. That is, we shouldn't be too hard-set on getting an exact fit.\n",
    "<li> The NQS is a simple model of the wave-function. It has much less number of parameters than the Hilbert space dimension and many papers have shown that it models the physically found wavefunctions well.\n",
    "</ol>\n",
    "\n",
    "Now if the NQS state cannot model the tomographic data then we have failed and nothing more is to be said.\n",
    "\n",
    "But if it does give a good fit, we can say: \"Not only have we reconstructed the wave-function but also since we have reconstructed a simple wave-function we have reduced the risk of overfitting.\"\n",
    "\n",
    "This is equivalent to what we say in the document:\n",
    "\n",
    "\"Such a compressed representation of the underlying probability distribution then reduces the risk of overfitting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
